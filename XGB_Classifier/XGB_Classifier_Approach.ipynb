{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here I will be loading the data from the cvs files to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops = pd.read_csv(\"...path to train.csv...\"\")\n",
    "crops_unknown = pd.read_csv(\"...path to test.csv...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing steps:\n",
    "        1) Define the features and the labels and label them as x and y\n",
    "        2) Fill the missing the data. Here I am using the data points before them to fill the missing data. \n",
    "        3) Then the features are transformed to decrease the skeweness of the features.\n",
    "        3) Then the data is scaled so that all the features have the same importance.\n",
    "        4) Then the data points are divided into the training set and evaluation set.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "x = crops.iloc[: , 1:9]\n",
    "y = crops.iloc[: , 9]\n",
    "\n",
    "#2\n",
    "x = x.fillna(method = \"bfill\" , axis = 0)\n",
    "x = np.sqrt(x)\n",
    "\n",
    "#3\n",
    "sc_x = StandardScaler()\n",
    "x = sc_x.fit_transform(x)\n",
    "\n",
    "#4\n",
    "x_train , x_test , y_train , y_test = split(x , y , test_size = 0.2 , stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing the imbalanced nature of the data\n",
    "Here I am not going to resample the data.\n",
    "\n",
    "Instead of that, I am going to create sample weights, which will give particular weights to various data points of different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateBalancedSampleWeights(y_train, largest_class_weight_coef):\n",
    "    classes = y_train.unique()\n",
    "    classes.sort()\n",
    "    class_samples = np.bincount(y_train)\n",
    "    total_samples = class_samples.sum()\n",
    "    n_classes = len(class_samples)\n",
    "    weights = total_samples / (n_classes * class_samples * 1.0)\n",
    "    class_weight_dict = {key : value for (key, value) in zip(classes, weights)}\n",
    "    class_weight_dict[classes[1]] = class_weight_dict[classes[1]] * largest_class_weight_coef\n",
    "    sample_weights = [class_weight_dict[y] for y in y_train]\n",
    "\n",
    "    return sample_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_weight = CreateBalancedSampleWeights(y_train, largest_class_weight_coef=0.2)\n",
    "xgb_clf = XGBClassifier(\n",
    "            n_estimators = 3000 , \n",
    "            max_depth = 20 , \n",
    "            gpu_id = 0 , \n",
    "            booster = \"gbtree\" , \n",
    "            gamma = 1 \n",
    "            \n",
    "            )\n",
    "xgb_clf.fit(x_train, y_train, sample_weight=train_sample_weight, eval_metric=accuracy_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score as acc_score\n",
    "accuracy = acc_score(y_test , y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test , y_pred , digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test , y_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "fileName = \"XGB_with_sampleWeights.sav\"\n",
    "joblib.dump(model , fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model and predicting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_unknown = crops_unknown.iloc[: , 1:9]\n",
    "crops_id = crops_unknown.iloc[: , 0]\n",
    "\n",
    "x_unknown = x_unknown.fillna(method = \"bfill\" , axis = 0)\n",
    "x_unknown = np.sqrt(x_unknown)\n",
    "\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "x_unknown = sc_x.fit_transform(x_unknown)\n",
    "\n",
    "\n",
    "y_unknown = xgb_clf.predict(x_unknown)\n",
    "\n",
    "submission = pd.DataFrame({'ID':crops_id, 'Crop_Damage':y_unknown})\n",
    "submission.to_csv('Submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
